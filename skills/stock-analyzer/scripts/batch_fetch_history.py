#!/usr/bin/env python3
"""
æ‰¹é‡èŽ·å–æ‰€æœ‰Aè‚¡åŽ†å²æ•°æ®
ç›®æ ‡ï¼šæ¯åªè‚¡ç¥¨è‡³å°‘1000æ¡æ•°æ®ï¼ˆ4å¹´åŽ†å²ï¼‰
æˆªæ­¢æ—¥æœŸï¼š2026å¹´2æœˆ6æ—¥
"""
import json
import time
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

# æˆªæ­¢æ—¥æœŸ
END_DATE = datetime(2026, 2, 6)
START_DATE = END_DATE - timedelta(days=1825)  # 5å¹´ (çº¦1250äº¤æ˜“æ—¥)

# Aè‚¡æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨ï¼ˆæµ‹è¯•ç”¨ï¼‰
TEST_STOCKS = [
    # æ²ªæ·±300
    ("600519", "è´µå·žèŒ…å°"),
    ("601398", "å·¥å•†é“¶è¡Œ"),
    ("600036", "æ‹›å•†é“¶è¡Œ"),
    ("601288", "å†œä¸šé“¶è¡Œ"),
    ("601988", "ä¸­å›½é“¶è¡Œ"),
    ("601939", "å»ºè®¾é“¶è¡Œ"),
    ("600030", "ä¸­ä¿¡è¯åˆ¸"),
    ("600028", "ä¸­å›½çŸ³åŒ–"),
    ("601857", "ä¸­å›½çŸ³æ²¹"),
    ("600016", "æ°‘ç”Ÿé“¶è¡Œ"),
    # ä¸­è¯500
    ("000338", "æ½æŸ´åŠ¨åŠ›"),
    ("002032", "è‹æ³Šå°”"),
    ("002594", "æ¯”äºšè¿ª"),
    ("002415", "æµ·åº·å¨è§†"),
    ("002466", "ä¸­çŽ¯è‚¡ä»½"),
    ("002371", "åŒ—æ–¹åŽåˆ›"),
    ("002475", "å¯Œå®‰å¨œ"),
    ("002511", "ä¸­é¡ºæ´æŸ”"),
    # åˆ›ä¸šæ¿
    ("300001", "ç‰¹é”å¾·"),
    ("300002", "ç¥žå·žæ³°å²³"),
    ("300003", "ä¹æ™®åŒ»ç–—"),
    ("300004", "å—é£Žè‚¡ä»½"),
    ("300005", "æŽ¢è·¯è€…"),
    ("300006", "èŽ±ç¾Žè¯ä¸š"),
    ("300007", "æ±‰å¨ç§‘æŠ€"),
    ("300008", "ä¸Šæµ·ä½³è±ª"),
    ("300009", "å®‰ç§‘ç”Ÿç‰©"),
    ("300010", "é¼Žé¾™è‚¡ä»½"),
    ("300012", "åŽæµ‹æ£€æµ‹"),
    ("300015", "çˆ±å°”çœ¼ç§‘"),
    ("300016", "æ™ºé£žç”Ÿç‰©"),
    ("300017", "ç½‘å®¿ç§‘æŠ€"),
    ("300018", "ä¸­ç§‘æ›™å…‰"),
    ("300019", "ç¡…å®ç§‘æŠ€"),
    ("300020", "é“¶æ±Ÿè‚¡ä»½"),
]

PROGRESS_FILE = Path.home() / ".config" / "deepseeker" / "stock_fetch_progress.json"


def load_progress():
    if PROGRESS_FILE.exists():
        with open(PROGRESS_FILE, 'r') as f:
            return json.load(f)
    return {"completed": [], "batch_index": 0, "total_fetched": 0}


def save_progress(progress):
    PROGRESS_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(PROGRESS_FILE, 'w') as f:
        json.dump(progress, f)


def fetch_history_akshare(symbol, name):
    """akshare èŽ·å–åŽ†å²æ•°æ®"""
    try:
        import akshare as ak
        
        df = ak.stock_zh_a_hist(
            symbol=symbol,
            period="daily",
            start_date=START_DATE.strftime("%Y%m%d"),
            end_date=END_DATE.strftime("%Y%m%d"),
            adjust="qfq"
        )
        
        if df is not None and not df.empty:
            df = df.rename(columns={
                'æ—¥æœŸ': 'date', 'å¼€ç›˜': 'open', 'æ”¶ç›˜': 'close',
                'æœ€é«˜': 'high', 'æœ€ä½Ž': 'low', 'æˆäº¤é‡': 'volume'
            })
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date')
            return df[['date', 'open', 'close', 'high', 'low', 'volume']], "akshare"
    
    except Exception as e:
        pass
    
    return None, None


def fetch_history_baostock(symbol, name):
    """baostock èŽ·å–åŽ†å²æ•°æ®"""
    try:
        import baostock as bs
        
        lg = bs.login()
        if lg.error_code != '0':
            return None, None
        
        bs_symbol = f"sh.{symbol}" if symbol.startswith('6') else f"sz.{symbol}"
        
        rs = bs.query_history_k_data_plus(
            bs_symbol,
            "date,open,high,low,close,volume",
            start_date=START_DATE.strftime("%Y-%m-%d"),
            end_date=END_DATE.strftime("%Y-%m-%d"),
            frequency="d",
            adjustflag="2"
        )
        
        data_list = []
        while (rs.error_code == '0') and rs.next():
            data_list.append(rs.get_row_data())
        
        bs.logout()
        
        if data_list:
            df = pd.DataFrame(data_list, columns=['date', 'open', 'high', 'low', 'close', 'volume'])
            for col in ['open', 'high', 'low', 'close', 'volume']:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date')
            return df, "baostock"
    
    except Exception as e:
        pass
    
    return None, None


def fetch_stock_history(symbol, name):
    """èŽ·å–å•åªè‚¡ç¥¨åŽ†å²æ•°æ®"""
    # ä¼˜å…ˆ akshare
    df, source = fetch_history_akshare(symbol, name)
    if df is not None:
        return df, source
    
    # å¤‡ç”¨ baostock
    time.sleep(0.3)
    df, source = fetch_history_baostock(symbol, name)
    if df is not None:
        return df, source
    
    return None, None


def save_to_csv(df, symbol):
    output_dir = Path("/home/liujerry/é‡‘èžæ•°æ®/stocks")
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / f"{symbol}.csv"
    df.to_csv(output_file, index=False, encoding='utf-8-sig')
    return output_file


def get_batch_stocks(batch_index, batch_size=50):
    progress = load_progress()
    
    if 'all_stocks' not in progress:
        stocks = TEST_STOCKS
        progress['all_stocks'] = stocks
        progress['batch_size'] = batch_size
        save_progress(progress)
    else:
        stocks = progress['all_stocks']
    
    start_idx = batch_index * batch_size
    end_idx = min(start_idx + batch_size, len(stocks))
    
    return stocks[start_idx:end_idx]


def batch_fetch_history(batch_index=0, batch_size=50):
    """æ‰¹é‡èŽ·å–åŽ†å²æ•°æ®"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    print("=" * 70)
    print("ðŸ“ˆ æ‰¹é‡èŽ·å–Aè‚¡åŽ†å²æ•°æ®")
    print(f"â° {timestamp}")
    print(f"ðŸ“… èŒƒå›´: {START_DATE.strftime('%Y-%m-%d')} ~ {END_DATE.strftime('%Y-%m-%d')}")
    print(f"ðŸ“¦ æ‰¹æ¬¡: {batch_index}, æ¯æ‰¹: {batch_size}åª")
    print("=" * 70)
    
    progress = load_progress()
    completed = set(progress.get('completed', []))
    stocks = get_batch_stocks(batch_index, batch_size)
    
    if not stocks:
        print("âœ… æ‰€æœ‰æ‰¹æ¬¡å·²å®Œæˆï¼")
        print(f"ðŸ“Š æ€»è®¡èŽ·å–: {progress.get('total_fetched', 0)} åªè‚¡ç¥¨")
        return
    
    success = failed = 0
    source_counts = {}
    
    for i, (symbol, name) in enumerate(stocks, 1):
        if symbol in completed:
            print(f"[{i}/{len(stocks)}] {symbol} ({name})... â­ï¸ å·²å®Œæˆ")
            continue
        
        print(f"[{i}/{len(stocks)}] {symbol} ({name})...", end=" ", flush=True)
        
        df, source = fetch_stock_history(symbol, name)
        
        if df is not None and not df.empty:
            save_to_csv(df, symbol)
            latest_date = df['date'].iloc[-1].strftime("%Y-%m-%d")
            records = len(df)
            print(f"âœ“ ({source}, {latest_date}, {records}æ¡)")
            
            if records >= 1000:
                print(f"   âœ… è¾¾æ ‡: {records}æ¡ â‰¥ 1000æ¡")
            else:
                print(f"   âš ï¸ ä»… {records}æ¡ (ç›®æ ‡: 1000æ¡)")
            
            success += 1
            source_counts[source] = source_counts.get(source, 0) + 1
            completed.add(symbol)
        else:
            print("âœ—")
            failed += 1
        
        time.sleep(0.5)
    
    progress['completed'] = list(completed)
    progress['total_fetched'] = progress.get('total_fetched', 0) + success
    progress['batch_index'] = batch_index
    progress['last_run'] = timestamp
    save_progress(progress)
    
    total_stocks = len(progress.get('all_stocks', TEST_STOCKS))
    completed_count = len(completed)
    progress_pct = (completed_count / total_stocks * 100) if total_stocks > 0 else 0
    
    print(f"\nðŸ“Š æœ¬æ‰¹æ¬¡å®Œæˆ: {success}, å¤±è´¥: {failed}")
    print(f"ðŸ“ˆ æ€»ä½“è¿›åº¦: {completed_count}/{total_stocks} ({progress_pct:.1f}%)")
    
    remaining = total_stocks - completed_count
    batches_left = (remaining + batch_size - 1) // batch_size
    
    print(f"ðŸ“… é¢„è®¡è¿˜éœ€ {batches_left} æ‰¹æ¬¡å®Œæˆå…¨éƒ¨")
    
    print("\n---OUTPUT_START---")
    result = {
        "status": "batch_complete",
        "batch_index": batch_index,
        "success": success,
        "failed": failed,
        "sources": source_counts,
        "progress": {
            "completed": completed_count,
            "total": total_stocks,
            "percentage": round(progress_pct, 2)
        },
        "timestamp": timestamp
    }
    print(json.dumps(result, ensure_ascii=False, indent=2))
    print("---OUTPUT_END---")


def check_data_quality():
    """æ£€æŸ¥æ•°æ®è´¨é‡"""
    print("\nðŸ“Š æ•°æ®è´¨é‡æ£€æŸ¥:")
    progress = load_progress()
    completed = progress.get('completed', [])
    
    qualified = 0
    for symbol in completed:
        file_path = Path(f"/home/liujerry/é‡‘èžæ•°æ®/stocks/{symbol}.csv")
        if file_path.exists():
            df = pd.read_csv(file_path)
            records = len(df)
            if records >= 1000:
                qualified += 1
                print(f"   âœ… {symbol}: {records}æ¡")
            else:
                print(f"   âš ï¸ {symbol}: {records}æ¡")
    
    print(f"\nðŸ“ˆ è¾¾æ ‡è‚¡ç¥¨: {qualified}/{len(completed)}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--check":
            progress = load_progress()
            print(json.dumps(progress, ensure_ascii=False, indent=2))
            check_data_quality()
        elif sys.argv[1] == "--reset":
            if PROGRESS_FILE.exists():
                PROGRESS_FILE.unlink()
            print("âœ… è¿›åº¦å·²é‡ç½®")
        elif sys.argv[1] == "--quality":
            check_data_quality()
        else:
            try:
                batch_index = int(sys.argv[1])
                batch_size = int(sys.argv[2]) if len(sys.argv) > 2 else 50
                batch_fetch_history(batch_index, batch_size)
            except:
                batch_fetch_history()
    else:
        batch_fetch_history()
