#!/usr/bin/env python3
"""
Aè‚¡é¢„æµ‹æ¨¡å‹éªŒè¯æµ‹è¯•
ä½¿ç”¨å†å²æ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œé¢„æµ‹2026å¹´2æœˆäº¤æ˜“æ•°æ®ï¼Œå¹¶ä¸çœŸå®æ•°æ®æ¯”å¯¹
"""
import os
import sys
import json
import warnings
from datetime import datetime, timedelta
from pathlib import Path
import numpy as np
import pandas as pd

warnings.filterwarnings('ignore')

# é…ç½®
DATA_DIR = Path("/home/liujerry/é‡‘èæ•°æ®/stocks")
OUTPUT_DIR = Path("/home/liujerry/é‡‘èæ•°æ®/predictions")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨ï¼ˆé€‰æ‹©ä¸åŒæ¿å—ï¼‰
TEST_STOCKS = [
    ("600519", "è´µå·èŒ…å°"),  # æ²ªå¸‚è“ç­¹
    ("601398", "å·¥å•†é“¶è¡Œ"),  # é“¶è¡Œ
    ("600030", "ä¸­ä¿¡è¯åˆ¸"),  # åˆ¸å•†
    ("000002", "ä¸‡  ç§‘ï¼¡"),  # æ·±å¸‚åœ°äº§
    ("300750", "å®å¾·æ—¶ä»£"),  # åˆ›ä¸šæ¿æ–°èƒ½æº
    ("002594", "æ¯”äºšè¿ª"),    # æ•´è½¦
    ("600028", "ä¸­å›½çŸ³åŒ–"),  # çŸ³æ²¹
    ("000651", "æ ¼åŠ›ç”µå™¨"),  # å®¶ç”µ
    ("300760", "è¿ˆä¸ºè‚¡ä»½"),  # åŒ»ç–—
    ("603986", "å…†æ˜“åˆ›æ–°"),  # èŠ¯ç‰‡
    ("600036", "æ‹›å•†é“¶è¡Œ"),  # é“¶è¡Œ
    ("000001", "å¹³å®‰é“¶è¡Œ"),  # é“¶è¡Œ
]

def load_stock_data(code):
    """åŠ è½½è‚¡ç¥¨æ•°æ®"""
    filepath = DATA_DIR / f"{code}.csv"
    if not filepath.exists():
        return None
    
    try:
        df = pd.read_csv(filepath, encoding='utf-8-sig')
        
        # æ ¹æ®åˆ—æ•°åˆ¤æ–­æ ¼å¼
        n_cols = df.shape[1]
        
        if n_cols == 2:
            # ç®€åŒ–æ ¼å¼: date, open -> date, close
            df.columns = ['date', 'close']
        elif n_cols == 6:
            # æ²ªå¸‚æ ¼å¼: date,open,high,low,close,volume
            pass  # åˆ—åå·²ç»æ­£ç¡®
        elif n_cols == 12:
            # å®Œæ•´å†å²æ ¼å¼
            df.columns = ['date', 'code', 'open', 'close', 'high', 'low', 
                         'volume', 'amount', 'amplitude', 'pct_change', 
                         'change', 'turnover']
            df = df[['date', 'open', 'close', 'high', 'low', 'volume']]
        else:
            print(f"  âš ï¸ æœªçŸ¥æ ¼å¼: {n_cols} åˆ—")
            return None
        
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date').reset_index(drop=True)
        
        # ç¡®ä¿æ•°å€¼åˆ—æ˜¯æ•°å€¼ç±»å‹
        for col in ['open', 'close', 'high', 'low']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        if 'volume' in df.columns:
            df['volume'] = pd.to_numeric(df['volume'], errors='coerce')
        
        # å¦‚æœæ²¡æœ‰volumeåˆ—ï¼Œåˆ›å»ºé»˜è®¤å€¼
        if 'volume' not in df.columns:
            df['volume'] = 1.0
        
        return df
    except Exception as e:
        print(f"åŠ è½½ {code} æ•°æ®å¤±è´¥: {e}")
        return None

def calculate_technical_features(df):
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾"""
    df = df.copy()
    
    # ä»·æ ¼ç‰¹å¾
    df['return'] = df['close'].pct_change()
    df['log_return'] = np.log(df['close'] / df['close'].shift(1))
    
    # ç§»åŠ¨å¹³å‡
    for window in [5, 10, 20, 60]:
        df[f'ma_{window}'] = df['close'].rolling(window=window).mean()
        df[f'ma_ratio_{window}'] = df['close'] / df[f'ma_{window}']
    
    # æ³¢åŠ¨ç‡
    df['volatility_5'] = df['return'].rolling(window=5).std()
    df['volatility_20'] = df['return'].rolling(window=20).std()
    
    # RSI
    for period in [7, 14, 21]:
        delta = df['close'].diff()
        gain = delta.where(delta > 0, 0).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        df[f'rsi_{period}'] = 100 - (100 / (1 + rs))
    
    # MACD
    ema_12 = df['close'].ewm(span=12, adjust=False).mean()
    ema_26 = df['close'].ewm(span=26, adjust=False).mean()
    df['macd'] = ema_12 - ema_26
    df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()
    df['macd_hist'] = df['macd'] - df['macd_signal']
    
    # å¸ƒæ—å¸¦
    for period in [20]:
        df[f'bb_mid_{period}'] = df['close'].rolling(window=period).mean()
        bb_std = df['close'].rolling(window=period).std()
        df[f'bb_upper_{period}'] = df[f'bb_mid_{period}'] + 2 * bb_std
        df[f'bb_lower_{period}'] = df[f'bb_mid_{period}'] - 2 * bb_std
        df[f'bb_width_{period}'] = (df[f'bb_upper_{period}'] - df[f'bb_lower_{period}']) / df[f'bb_mid_{period}']
        df[f'bb_position_{period}'] = (df['close'] - df[f'bb_lower_{period}']) / (df[f'bb_upper_{period}'] - df[f'bb_lower_{period}'])
    
    # æˆäº¤é‡ç‰¹å¾
    df['volume_ma_5'] = df['volume'].rolling(window=5).mean()
    df['volume_ratio'] = df['volume'] / df['volume_ma_5']
    
    # åŠ¨é‡
    for period in [5, 10, 20]:
        df[f'momentum_{period}'] = df['close'] / df['close'].shift(period) - 1
    
    return df

def prepare_features(df, feature_cols):
    """å‡†å¤‡ç‰¹å¾çŸ©é˜µ"""
    df_clean = df.dropna(subset=feature_cols).copy()
    return df_clean

def train_lstm_model(X_train, y_train):
    """ç®€å•LSTMæ¨¡å‹ï¼ˆä½¿ç”¨sklearnçš„MLPæ›¿ä»£ï¼‰"""
    from sklearn.neural_network import MLPRegressor
    from sklearn.preprocessing import StandardScaler
    
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_train)
    
    model = MLPRegressor(
        hidden_layer_sizes=(64, 32),
        activation='relu',
        solver='adam',
        max_iter=500,
        random_state=42,
        early_stopping=True,
        validation_fraction=0.1
    )
    model.fit(X_scaled, y_train)
    
    return model, scaler

def train_xgboost_model(X_train, y_train):
    """XGBoostæ¨¡å‹"""
    try:
        import xgboost as xgb
        
        model = xgb.XGBRegressor(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)
        return model
    except (ImportError, ModuleNotFoundError):
        print("  âš ï¸ XGBoostæœªå®‰è£…ï¼Œä½¿ç”¨éšæœºæ£®æ—æ›¿ä»£")
        from sklearn.ensemble import RandomForestRegressor
        model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)
        model.fit(X_train, y_train)
        return model

def predict_next_day(model, scaler, last_features, model_type='lstm'):
    """é¢„æµ‹ä¸‹ä¸€å¤©ä»·æ ¼"""
    if model_type == 'lstm':
        X = scaler.transform(last_features.reshape(1, -1))
    else:
        X = last_features.reshape(1, -1)
    
    pred = model.predict(X)[0]
    return pred

def evaluate_prediction(actual, predicted):
    """è¯„ä¼°é¢„æµ‹å‡†ç¡®æ€§"""
    actual = np.array(actual)
    predicted = np.array(predicted)
    
    # è®¡ç®—å„ç§è¯¯å·®æŒ‡æ ‡
    mae = np.mean(np.abs(actual - predicted))
    rmse = np.sqrt(np.mean((actual - predicted) ** 2))
    mape = np.mean(np.abs((actual - predicted) / actual)) * 100
    
    # æ–¹å‘å‡†ç¡®ç‡
    actual_dir = np.sign(np.diff(actual))
    pred_dir = np.sign(np.diff(predicted))
    direction_acc = np.mean(actual_dir == pred_dir) * 100
    
    return {
        'MAE': mae,
        'RMSE': rmse,
        'MAPE': mape,
        'direction_accuracy': direction_acc
    }

def run_prediction_test():
    """è¿è¡Œé¢„æµ‹æµ‹è¯•"""
    print("=" * 80)
    print("ğŸ¤– Aè‚¡é¢„æµ‹æ¨¡å‹éªŒè¯æµ‹è¯•")
    print("=" * 80)
    print(f"\nğŸ“… æµ‹è¯•æ—¥æœŸèŒƒå›´: 2026-02-01 ~ 2026-02-06")
    print(f"ğŸ“Š æµ‹è¯•è‚¡ç¥¨æ•°é‡: {len(TEST_STOCKS)}")
    
    # ç‰¹å¾åˆ—
    feature_cols = [
        'return', 'log_return', 'ma_ratio_5', 'ma_ratio_10', 'ma_ratio_20',
        'volatility_5', 'volatility_20', 'rsi_14', 'macd', 'macd_signal',
        'macd_hist', 'bb_position_20', 'volume_ratio', 'momentum_5', 'momentum_10'
    ]
    
    results = []
    
    for code, name in TEST_STOCKS:
        print(f"\n{'='*60}")
        print(f"ğŸ“ˆ æµ‹è¯• {code} ({name})")
        print(f"{'='*60}")
        
        # åŠ è½½æ•°æ®
        df = load_stock_data(code)
        if df is None or len(df) < 100:
            print(f"  âŒ æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
            continue
        
        # è®¡ç®—ç‰¹å¾
        df = calculate_technical_features(df)
        
        # åˆ†ç¦»è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®
        # è®­ç»ƒ: 2021-01-01 ~ 2026-01-31
        # æµ‹è¯•: 2026-02-01 ~ 2026-02-06
        train_df = df[df['date'] < '2026-02-01'].copy()
        test_df = df[(df['date'] >= '2026-02-01') & (df['date'] <= '2026-02-06')].copy()
        
        if len(test_df) < 3:
            print(f"  âŒ æµ‹è¯•æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
            continue
        
        train_df = prepare_features(train_df, feature_cols)
        
        if len(train_df) < 50:
            print(f"  âŒ è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
            continue
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        X_train = train_df[feature_cols].values
        y_train = train_df['close'].values
        
        # è®­ç»ƒæ¨¡å‹
        print(f"  ğŸ“Š è®­ç»ƒæ•°æ®: {len(train_df)} æ¡")
        print(f"  ğŸ“Š æµ‹è¯•æ•°æ®: {len(test_df)} æ¡")
        
        # XGBoostæ¨¡å‹
        xgb_model = train_xgboost_model(X_train, y_train)
        
        # é¢„æµ‹
        predictions = []
        actuals = []
        dates = []
        
        for idx, row in test_df.iterrows():
            features = row[feature_cols].values.astype(float)
            
            if not np.any(np.isnan(features)):
                pred = xgb_model.predict(features.reshape(1, -1))[0]
                predictions.append(pred)
                actuals.append(row['close'])
                dates.append(row['date'])
        
        if len(predictions) < 2:
            print(f"  âŒ é¢„æµ‹ç»“æœä¸è¶³ï¼Œè·³è¿‡")
            continue
        
        # è¯„ä¼°
        metrics = evaluate_prediction(actuals, predictions)
        
        print(f"\n  ğŸ“Š é¢„æµ‹ç»“æœ:")
        print(f"     é¢„æµ‹å¤©æ•°: {len(predictions)}")
        print(f"     MAE: {metrics['MAE']:.2f}")
        print(f"     RMSE: {metrics['RMSE']:.2f}")
        print(f"     MAPE: {metrics['MAPE']:.2f}%")
        print(f"     æ–¹å‘å‡†ç¡®ç‡: {metrics['direction_accuracy']:.1f}%")
        
        print(f"\n  ğŸ“ˆ ä»·æ ¼å¯¹æ¯”:")
        for i, (date, actual, pred) in enumerate(zip(dates[:5], actuals[:5], predictions[:5])):
            error_pct = (pred - actual) / actual * 100
            direction = "âœ“" if np.sign(pred - actuals[i-1]) == np.sign(actual - actuals[i-1]) else "âœ—" if i > 0 else "-"
            print(f"     {date.strftime('%Y-%m-%d')}: å®é™…={actual:.2f}, é¢„æµ‹={pred:.2f}, è¯¯å·®={error_pct:+.1f}% {direction}")
        
        results.append({
            'code': code,
            'name': name,
            'actual_last': actuals[-1],
            'predicted_last': predictions[-1],
            'mape': metrics['MAPE'],
            'direction_acc': metrics['direction_accuracy'],
            'predictions': predictions,
            'actuals': actuals,
            'dates': [str(d) for d in dates]
        })
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š é¢„æµ‹ç»“æœæ±‡æ€»")
    print("=" * 80)
    
    if not results:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æµ‹è¯•ç»“æœ")
        return
    
    # è®¡ç®—æ€»ä½“æŒ‡æ ‡
    total_mape = np.mean([r['mape'] for r in results])
    total_dir_acc = np.mean([r['direction_acc'] for r in results])
    
    print(f"\nâœ… æˆåŠŸæµ‹è¯• {len(results)} åªè‚¡ç¥¨")
    print(f"ğŸ“Š å¹³å‡MAPE: {total_mape:.2f}%")
    print(f"ğŸ“Š å¹³å‡æ–¹å‘å‡†ç¡®ç‡: {total_dir_acc:.1f}%")
    
    print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
    print("-" * 80)
    print(f"{'ä»£ç ':<10} {'åç§°':<10} {'å®é™…æ”¶ç›˜':<12} {'é¢„æµ‹æ”¶ç›˜':<12} {'MAPE':<10} {'æ–¹å‘å‡†ç¡®ç‡':<10}")
    print("-" * 80)
    
    for r in sorted(results, key=lambda x: x['mape']):
        print(f"{r['code']:<10} {r['name']:<10} {r['actual_last']:<12.2f} {r['predicted_last']:<12.2f} {r['mape']:<10.2f}% {r['direction_acc']:<10.1f}%")
    
    # ä¿å­˜ç»“æœ
    output_file = OUTPUT_DIR / "prediction_test_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'test_date': datetime.now().isoformat(),
            'stocks_tested': len(results),
            'total_mape': total_mape,
            'total_direction_accuracy': total_dir_acc,
            'results': results
        }, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {output_file}")
    
    return results

if __name__ == "__main__":
    run_prediction_test()
